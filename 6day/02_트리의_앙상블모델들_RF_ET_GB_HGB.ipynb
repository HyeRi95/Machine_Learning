{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df480f99",
   "metadata": {},
   "source": [
    "## 트리의 앙상블 (이진분류 할필요 x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d034f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정형데이터에 가장 뛰어난 성능을 보이는 모델들 입니다\n",
    "# 앙상블 모델들은 결정트리(Decision Tree)를 기반으로 만들어 졌습니다\n",
    "# 앙상블 모델들\n",
    "# - 랜덤포레스트(Random Forest)\n",
    "# - 엑스트라 트리(Extra Trees)\n",
    "# - 그래디언트 부스팅(Gradient Boosting)\n",
    "# - 히스토그램 기반 그래디언트 부스팅(Histogram-base Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5947337",
   "metadata": {},
   "source": [
    "## 랜덤포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da60fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - 앙상블 모델 중에 가장 대표격 모델로 사용됨\n",
    "### - 안정적인 성능으로 널리 사용\n",
    "### - 앙상블 모델 중에 가장 먼저 시도하는 모델\n",
    "### - 훈련데이터에서 과대적합되는 것을 막아준다\n",
    "### - 검증 데이터와 테스트데이터에서 안정적인 성능을 얻을 수 있음\n",
    "\n",
    "### 학습개념 \n",
    "### - 결정트리를 하나하나를 랜덤하게 만들어서 숲을 만들기\n",
    "### - 훈련데이터에서 랜덤하게 샘플을 추출하여 훈련을 완료한 후 다시 원본 훈련데이터에반환\n",
    "### - 랜덤하게 추출 시 이전에 사용된 샘플을 사용할 수도 있음 (중복허용)\n",
    "\n",
    "### 부트스트랩 샘플(Bootstrap Sample)\n",
    "### - 위에 설명한 랜덤한 샘플 추출 시 중복을 허용하여 데이터를 샘플링 하는 방식\n",
    "### - 샘플 추출방식\n",
    "###   1. 원본에서 랜덤샘플 추출\n",
    "###   2.훈련 이후 사용이 끝나면 원본에 반환\n",
    "###   3.다시 원본에서 샘플 추출, 이때 중복 값 추출될수도있다\n",
    "#### - 위 순사를 반복하면서 샘플링을 통해 훈련하는 방식을 랜덤포레스트가 적용하고있다 \n",
    "\n",
    "\n",
    "### **** 랜덤포레스트는 교차검증을 허용 ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb5df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382236f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4872, 3) (4872,)\n",
      "(1625, 3) (1625,)\n"
     ]
    }
   ],
   "source": [
    "wine = pd.read_csv('./data/08_wine.csv')\n",
    "data=wine[['alcohol','sugar','pH']].to_numpy()\n",
    "target=wine['class'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(data,target, random_state=42)\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(test_input.shape, test_target.shape)\n",
    "\n",
    "# 표준화(정규화) 작업도 해주면 좋다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d17b35",
   "metadata": {},
   "source": [
    "### 훈련모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8c0855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.25937247, 0.25969505, 0.26253867, 0.26479316, 0.2518723 ]), 'score_time': array([0.03181005, 0.03842092, 0.03265023, 0.03263855, 0.03037333]), 'test_score': array([0.88      , 0.90051282, 0.90349076, 0.89014374, 0.88295688]), 'train_score': array([0.99743392, 0.99692071, 0.99846075, 0.99820421, 0.99820421])}\n",
      "0.997844759088341 0.8914208392565683\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트 패키지 : sklearn.ensemble\n",
    "# 랜덤포레스트 클래스(모델) : RandomForestClassifier\n",
    "# 교차검증 패키지 : sklearn.model_selection\n",
    "# 교차검증 : cross_validate()\n",
    "# 교차검증 후 훈련검증 결과와 테스트검증결과 확인하기\n",
    "\n",
    "# 랜덤포레스트 객체생성 : 코어 모두 사용\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs= -1 , random_state=42)\n",
    "\n",
    "# 교차검증 진행\n",
    "# - return_train_score : 검증결과 반환받기\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(rfc,train_input, train_target, return_train_score = True, n_jobs=-1)\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "print(scores)\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d18305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23155241 0.49706658 0.27138101]\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(train_input , train_target)\n",
    "## 특성중요도 조회하기\n",
    "# 랜덤포레스트 여러가지 골고루 사용 \n",
    "print(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43cb3e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981937602627258\n"
     ]
    }
   ],
   "source": [
    "### 기능 사용\n",
    "# 훈련에 참여하지 못한 잔여샘플 사용하는 기능 \n",
    "#기본은 사용X\n",
    "rfc = RandomForestClassifier(oob_score =True, n_jobs = -1 , random_state=42)\n",
    "rfc.fit(train_input, train_target)\n",
    "print(rfc.oob_score_)\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6706ced",
   "metadata": {},
   "source": [
    "### 엑스트라 트리(Extra Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7323000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 랜덤포레스트와 유사하게 작동\n",
    "# - 기본적으로 100개의 결정트리를 훈련함\n",
    "# - 랜덤포레스트와의 차이점\n",
    "#   : 부트스트랩 샘플링을 지원하지 않음\n",
    "#    : 훈련 데이터 전체를 이용하여 결정트리를 생성\n",
    "#   : 무작위로 트리를 분리함\n",
    "# - 사용되는 속성 :splitter = 'random' 무작위 속성\n",
    "# - 장점 \n",
    "#   : 과대적합을 막고, 검증데이터의 평가 값을 높일 수 있음\n",
    "#   : 특성 대이터가 많지 않은 경우에는 랜덤포레스트와 큰 차이가 없음\n",
    "# - 랜덤포레스트는 분순도등 여러가지 조건에 따라 결정 트리를 생성하기 떄문에 속도가 느린 바면\n",
    "# - 엑스트라트리는 랜덤하게 결정트리를 생성하기에 속도가 다소 빠르다는 장점 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e7ee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997844759088341 0.8903937240035804\n"
     ]
    }
   ],
   "source": [
    "### 사용패키지 : 랜덤포레스트와 동일\n",
    "# 사용되는 클래스(모델) : ExtraTreesClassifier\n",
    "\n",
    "### 코어 전체 사용, train 및 test 결과값 출력\n",
    "### 교차검증 train 및 test 결과 확인\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(n_jobs= -1 , random_state=42)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(etc,train_input, train_target,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증 결과\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363392c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20702369 0.51313261 0.2798437 ]\n"
     ]
    }
   ],
   "source": [
    "etc.fit(train_input, train_target)\n",
    "print(etc.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b1424",
   "metadata": {},
   "source": [
    "## 그래디언트 부스팅 ( Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d68dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 깊이 (max_depth)가 얕은 결정트리를 사용\n",
    "# - 기본적으로 max_depth =3 을 사용\n",
    "# - 결정트리는 100개 사용\n",
    "### *** 기존에 다른 훈련모델의 결과가 좋지않을때 사용하는 모델 ****\n",
    "# 기존 훈련모델의 오차를 많이 보완\n",
    "# 성능 향상을 위한 모델로 주로 사용\n",
    "# 과대적합에 강하며, 일반화(과대/과소적합이 없는 상태)에 강함\n",
    "\n",
    "# 성능향상 테스트 방법\n",
    "# - 결정트리의 갯수를 조절하면서 테스트 진행 \n",
    "# - 학습률을 지원하기 때문에 학습률의 값을 증가시키면서 테스트 진행\n",
    "#   : 기본 학습률은 0.1\n",
    "\n",
    "# 단점\n",
    "# - 순서대로 트리를 추가(랜덤하지 않음)하지 않기 때문에 훈련속도는 느림\n",
    "# - 이런 느린 속도를 개선한 모델이 ' 히스토그램 기반 그래디언트 부스팅' 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c7fcd",
   "metadata": {},
   "source": [
    "## 그래디언트 부스팅 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612ca7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8894704231708938 0.8715107671247301\n"
     ]
    }
   ],
   "source": [
    "### 사용하는 클래스 (모델) : GradientBoostingClassifier\n",
    "# 객체 생성시 아무것도 안주고 seed 값만 줍니다\n",
    "# 교차검증시에는 train, test 결과값 출력\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(gdc,train_input, train_target,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증 결과\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n",
    "\n",
    "\n",
    "# 0.997844759088341 0.8914208392565683   : 랜덤포레스트\n",
    "# 0.997844759088341 0.8903937240035804   : 엑스트라 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8de69a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12517641 0.73300095 0.14182264]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gdc.fit(train_input, train_target)\n",
    "print(gdc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2efbf39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8578461538461538"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdc.score(test_input,test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a22a5c",
   "metadata": {},
   "source": [
    "## 학습률 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "258b1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률이 커지면 트리 보정을 강하게 하기때문에 복잡한 모델을 만들어서 일반화 성능을 떨어뜨리게된다\n",
    "# 학습률 : learning_rate=0.1 기본값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9dbfdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8894704231708938 0.8715107671247301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdc = GradientBoostingClassifier(n_estimators=100,\n",
    "                                 learning_rate=0.1,\n",
    "                                 random_state=42)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(gdc,train_input, train_target,return_train_score=True,n_jobs=-1)\n",
    "scores\n",
    "# 최종 훈련평가 결과 및 검증 결과\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab69bb8",
   "metadata": {},
   "source": [
    "## 히스토그램 기반 그래디언트 부스팅 \n",
    "####  - Histogram-base Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6e0b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9380129799494501 0.8805410414363187\n"
     ]
    }
   ],
   "source": [
    "## 사용하는 클래스(모델) : HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hgbc = HistGradientBoostingClassifier(random_state=42)\n",
    "scores= cross_validate(hgbc,train_input, train_target,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46440c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584615384615385"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgbc.fit(train_input, train_target)\n",
    "hgbc.score(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635b8bc",
   "metadata": {},
   "source": [
    "## sklearn이외 다른 패키지에서 지원하는\n",
    "## 히스토그램 기반 그래디언트 부스팅 기능 모델들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c7d76",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
    "scores=cross_validate(xgb, train_input, train_target,\n",
    "                     return_train_score=True, n_jobs=-1)\n",
    "\n",
    "scores\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd90791",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6245cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - a마이크로스프트에서 만든 히스토그램 기반 그래디언트 부스트 패키지\n",
    "# - 훈련속도가 매우빠름\n",
    "# - 최신 기술을 많이 적용하고 있어서 인기가 올라가고있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 사용시 : conda install -c conda-forge lightgbm\n",
    "# 파이썬 사용시 : pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = XGBClassifier(random_state=42)\n",
    "scores=cross_validate(lgb, train_input, train_target,\n",
    "                     return_train_score=True, n_jobs=-1)\n",
    "\n",
    "scores\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kernel",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
